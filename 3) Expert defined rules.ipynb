{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this file we assume the rules were given by an expert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as close as the PFS system gets to the workflow of the `normal` Fuzzy System Workflow. Please check out notebook 1 and 2 if you haven't already. It will make more sense if you read the notebooks in recommended order. What this file illustrated is how you could make prediction in a non-automatic way using rules defined by an expert for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import isclose\n",
    "from numpy.lib.function_base import append\n",
    "from simpful import *\n",
    "from simpful.rules import swap_none\n",
    "from modules.evolutiongp_multi__ import FuzzyEvolution\n",
    "from numpy import load\n",
    "import time\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rules.pkl', 'rb') as input:\n",
    "    rules = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate expert knowledge by taking the best model we found in the automatic rule search\n",
    "\n",
    "#### (act as if the automatic generated model was given by an expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IF (fare IS cluster0) OR (passclass IS cluster0) AND_p (parentchild IS cluster0) THEN P(OUTCOME IS DEATH)=0.617, P(OUTCOME IS ALIVE)=0.383',\n",
       " 'IF (NOT (sex IS cluster1)) AND (embarked IS cluster1) OR (passclass IS cluster1) AND (age IS cluster1) THEN P(OUTCOME IS DEATH)=0.0, P(OUTCOME IS ALIVE)=1.0',\n",
       " 'IF (NOT (parentchild IS cluster2)) THEN P(OUTCOME IS DEATH)=0.71, P(OUTCOME IS ALIVE)=0.29']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with Simpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_train observation_based\n",
    "X = np.load('./inputs_processed_/X_train.npy')\n",
    "\n",
    "# X_test observation bassed\n",
    "X_T = np.load('./inputs_processed_/X_test.npy')\n",
    "\n",
    "# correspinding y_train and test\n",
    "y = np.load(\"./inputs_processed_/y_train.npy\").tolist()\n",
    "y = [item for sublist in y for item in sublist]\n",
    "y_test = np.load(\"./inputs_processed_/y_test.npy\").tolist()\n",
    "y_test = [item for sublist in y_test for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is important to maintain the order of the dataset when specifying the vars. The order of the consequents should correspond to the way the rules were defined. E.g. :\n",
    "\n",
    "1. 'IF (fare IS cluster0) OR (passclass IS cluster0) AND_p (parentchild IS cluster0) THEN P(OUTCOME IS DEATH)=0.617, P(OUTCOME IS ALIVE)=0.383'\n",
    "\n",
    "Death should therefore be the first consequent term in each rule and alive should be the second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize using var_names/ consequents\n",
    "vars = ['passclass', 'sex', 'age', 'sibling', 'parentchild', 'fare', 'embarked']\n",
    "consequents = ['DEATH', 'ALIVE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuming we have a test set and a train set we can initialise as follows. Many options are possible. For more information we recommend reading the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_model = ProbaFuzzySystem(consequents=consequents, var_names=vars, X=X, X_test=X_T, y=y, y_test=y_test, pred_test=True, _return_class=True, generateprobas=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Comment out for docstring on ProbaFuzzySystem\n",
    "\n",
    "# help(ProbaFuzzySystem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we load the rules that we generated using automatic modelling. The idea is however that you can specify whatever rules you like with whatever probabilities you like. To show however that it leads to the same results as a verification step here we use the model which was found in notebook 1: 1) Titanic Model - Automatic modeling using Genetic Programming\n",
    "\n",
    "- As can be seen below the accuracy matches, for the comparison check out file 2) which shows an accuracy of 0.8100558659217877 and compare it for yourself to the one shown below (in the last cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_model.add_proba_rules(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What X_reformatter is make sure the rules are interpreted in the right way (but in the order of the `` vars `` variable. You usually give the whole dataset and the variables will be read correctly regardless thanks to the X_reformatter function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_model.X_reformatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a convenience method for adding the right linguistic variables all at once  (Keep in mind that the datasets, variables and all relevant information was loaden during intialisation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_model.add_linguistic_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions (Keep in mind that the datasets, variables and all relevant information was loaden during intialisation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = expert_model.predict_pfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predictions below are based on the test set (as user defined: ``pred_test=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_model.evaluate_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
